% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run.R
\name{run_benchmark}
\alias{run_benchmark}
\title{Run a Benchmark across a range of parameters}
\usage{
run_benchmark(
  bm,
  ...,
  params = default_params(bm, ...),
  n_iter = 1,
  dry_run = FALSE,
  profiling = FALSE,
  read_only = FALSE
)
}
\arguments{
\item{bm}{\code{\link[=Benchmark]{Benchmark()}} object}

\item{...}{Optional benchmark parameters to run across}

\item{params}{\code{data.frame} of parameter combinations. By default, this will
be constructed from the expansion of the \code{...} arguments, the declared
parameter options in \code{bm$setup}, and any restrictions potentially defined in
\code{bm$valid_params()}.}

\item{n_iter}{integer number of iterations to replicate each benchmark}

\item{dry_run}{logical: just return the R source code that would be run in
a subprocess? Default is \code{FALSE}, meaning that the benchmarks will be run.}

\item{profiling}{Logical: collect prof info? If \code{TRUE}, the result data will
contain a \code{prof_file} field, which you can read in with
\code{profvis::profvis(prof_input = file)}. Default is \code{FALSE}}

\item{read_only}{this will only attempt to read benchmark files and will not
run any that it cannot find.}
}
\value{
A \code{BenchmarkResults} object, containing \code{results} attribute of a list
of length \code{nrow(params)} each of those either a \code{BenchmarkResult} or
\code{BenchmarkFalure} object.
For a simpler view of results, call \code{as.data.frame()} on it.
}
\description{
Run a Benchmark across a range of parameters
}
