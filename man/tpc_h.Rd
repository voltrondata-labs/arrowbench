% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bm-tpc-h.R
\docType{data}
\name{tpc_h}
\alias{tpc_h}
\title{Benchmark TPC-H queries}
\format{
An object of class \code{Benchmark} of length 11.
}
\usage{
tpc_h
}
\description{
Benchmark TPC-H queries
}
\section{Parameters}{

\itemize{
\item \code{engine} One of \code{c("arrow", "duckdb", "dplyr")}
\item \code{query_id} integer, 1-22
\item \code{format} One of \code{c("parquet", "feather", "native")}
\item \code{scale_factor} Scale factor to use for data generation (e.g. 0.1, 1, 10, 100)
\item \code{memory_map} Should memory mapping be used when reading a file in? (only
applicable to arrow, native. \code{FALSE} will result in the file being explicitly
read into memory before the benchmark)
\item \code{output} the format of the output (either \code{"data_frame"} (default) or \code{"arrow_table"})
\item \code{chunk_size} a size of row groups to aim for in parquet or feather files (default:
NULL is the default for \code{arrow:write_parquet()} or \code{arrow::write_feather()})
}
}

\keyword{datasets}
